import pandas as pd
from rapidfuzz import fuzz
from pythainlp.tokenize import word_tokenize

# -------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
# -------------------
def segment_thai(text):
    """‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥"""
    if not text or pd.isna(text):
        return []
    words = word_tokenize(str(text), engine='newmm')
    return words

# -------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á n-grams
# -------------------
def create_ngrams(words, n):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á n-grams ‡∏à‡∏≤‡∏Å list ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥"""
    ngrams = []
    for i in range(len(words) - n + 1):
        ngram = ''.join(words[i:i+n])
        ngrams.append(ngram)
    return ngrams

# -------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô fuzzy match ‡πÅ‡∏ö‡∏ö dynamic n-gram
# -------------------
def find_typo_with_ngrams_dynamic(text, keyword, fuzz_thresh=80, min_length_ratio=0.9):
    text_words = segment_thai(text)
    keyword_words = segment_thai(keyword)
    n = len(keyword_words)
    keyword_joined = ''.join(keyword_words)

    max_score = 0
    best_match = None

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á n-grams ‡∏Ç‡∏ô‡∏≤‡∏î n-1, n, n+1
    for size in range(max(1, n-1), n+2):
        ngrams = create_ngrams(text_words, size)
        for ngram in ngrams:
            score = fuzz.ratio(ngram, keyword_joined)
            if len(ngram)/len(keyword_joined) >= min_length_ratio:
                if score > max_score:
                    max_score = score
                    best_match = ngram

    # fallback: ‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    if max_score < fuzz_thresh:
        text_joined = ''.join(text_words)
        score = fuzz.ratio(text_joined, keyword_joined)
        if score > max_score and len(text_joined)/len(keyword_joined) >= min_length_ratio:
            max_score = score
            best_match = text_joined

    is_match = max_score >= fuzz_thresh
    return is_match, max_score, best_match

# -------------------
# ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏µ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ "‡πÄ‡∏ã‡∏ï‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î"
# -------------------
def find_typo_multiple_keyword_sets_dynamic(text, keyword_sets, fuzz_thresh=80, min_length_ratio=0.9):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏ã‡∏ï keyword ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÄ‡∏ã‡∏ï‡πÉ‡∏î‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥ ‚Üí ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤ relevant
    """
    for kw_set in keyword_sets:
        matches = []
        for kw in kw_set:
            is_match, score, matched_text = find_typo_with_ngrams_dynamic(
                text, kw, fuzz_thresh=fuzz_thresh, min_length_ratio=min_length_ratio
            )
            matches.append((kw, is_match, score, matched_text))

        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡πÉ‡∏ô‡πÄ‡∏ã‡∏ï‡∏ô‡∏µ‡πâ
        if all(m[1] for m in matches):
            best_score = sum(m[2] for m in matches) / len(matches)
            matched_keywords = [m[0] for m in matches]
            matched_texts = [m[3] for m in matches]
            return True, matched_keywords, best_score, matched_texts

    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡πÄ‡∏ã‡∏ï‡πÄ‡∏•‡∏¢
    return False, None, 0, None

# -------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏•‡∏ö blacklist
# -------------------
def remove_blacklist_exact(text, blacklist):
    for bl in blacklist:
        text = text.replace(bl, "")
    return text

# -------------------
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå, keywords ‡πÅ‡∏•‡∏∞ blacklist
# -------------------
input_file = "CMPC_Monthly_20250531.xlsx"
output_file = "../outputfile/CMPC_Monthly_relevant1.xlsx"

keyword_sets = [
    ["‡∏Ñ‡∏∏‡∏ì‡∏™‡∏π‡πâ‡πÄ‡∏£‡∏≤‡∏ä‡πà‡∏ß‡∏¢"],
    # ["‡πÄ‡∏£‡∏≤‡∏ä‡πà‡∏ß‡∏¢"],
    # ['‡πÑ‡∏ñ‡πà‡∏ñ‡∏≠‡∏ô']
    ["‡πÑ‡∏ñ‡πà‡∏ñ‡∏≠‡∏ô", "‡πÇ‡∏â‡∏ô‡∏î"]
]

BLACKLIST = ["‡∏Å‡∏≤‡∏£", "‡∏Ñ‡∏ß‡∏≤‡∏°"]
FUZZY_THRESHOLD = 80
MIN_LENGTH_RATIO = 0.7 #0.9

# -------------------
# ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel
# -------------------
print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå...")
df = pd.read_excel(input_file)

if '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î' not in df.columns:
    raise ValueError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel")

# -------------------
# ‡∏•‡∏ö blacklist ‡∏Å‡πà‡∏≠‡∏ô‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥
# -------------------
df['‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î_cleaned'] = df['‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î'].apply(
    lambda x: remove_blacklist_exact(str(x), BLACKLIST)
)

# -------------------
# ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏π‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå)
# -------------------
print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥...")
df['‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î_‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥'] = df['‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î_cleaned'].apply(
    lambda x: ' | '.join(segment_thai(str(x)))
)

# -------------------
# ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î (‡πÅ‡∏ö‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏ã‡∏ï)
# -------------------
print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö {len(keyword_sets)} ‡πÄ‡∏ã‡∏ï‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î (threshold={FUZZY_THRESHOLD})...")
relevance_results = df['‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î_cleaned'].apply(
    lambda x: find_typo_multiple_keyword_sets_dynamic(
        str(x), keyword_sets, fuzz_thresh=FUZZY_THRESHOLD, min_length_ratio=MIN_LENGTH_RATIO
    )
)

df['Relevant'] = [r[0] for r in relevance_results]
df['Matched_keyword'] = [', '.join(r[1]) if r[1] else None for r in relevance_results]
df['Fuzzy_score'] = [r[2] for r in relevance_results]
df['Matched_word_in_text'] = [', '.join(r[3]) if r[3] else None for r in relevance_results]

# -------------------
# ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
# -------------------
df_relevant = df[df['Relevant']]

# -------------------
# ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
# -------------------
print(f"\n{'='*60}")
print(f"üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
print(f"{'='*60}")
print(f"‚úÖ ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {len(df_relevant)} / {len(df)} ‡πÅ‡∏ñ‡∏ß")
if len(df) > 0:
    print(f"üìà ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ: {len(df_relevant)/len(df)*100:.2f}%")

if len(df_relevant) > 0:
    print(f"\nüîç ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Keyword Set:")
    for kw_set in keyword_sets:
        kw_label = ' + '.join(kw_set)
        count = df_relevant[df_relevant['Matched_keyword'].str.contains(kw_set[0], na=False)].shape[0]
        print(f"   ‚Ä¢ {kw_label}: {count} ‡πÅ‡∏ñ‡∏ß")

# -------------------
# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
# -------------------
df_relevant.to_excel(output_file, index=False)
print(f"\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {output_file}")

# -------------------
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
# -------------------
if len(df_relevant) > 0:
    print(f"\nüìã ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å:")
    sample_cols = ['Matched_keyword', 'Matched_word_in_text', 'Fuzzy_score']
    print(df_relevant[sample_cols].head().to_string(index=False))
